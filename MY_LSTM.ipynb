{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a73fe881",
   "metadata": {},
   "source": [
    "## 利用LSTM进行负荷预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bed6623",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70929d7d",
   "metadata": {},
   "source": [
    "程序架构：\n",
    "1. 文件读取\n",
    "2. 数据预处理\n",
    "    - 转化为df\n",
    "    - 归一化\n",
    "    - 转化为监督学习df\n",
    "    - 数据集分割(6:2:2)\n",
    "3. 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42fb6d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import requests\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892926cd",
   "metadata": {},
   "source": [
    "# Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9cf341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "\n",
    "file_path = r'C:\\Users\\KAI\\Source\\kais_lstm_load_forecasting\\A_10000151_1.csv'\n",
    "\n",
    "# 第一行做列名(header)\\第一列做索引(id)\\解析第二列为日期\n",
    "# 参考https://www.cnblogs.com/traditional/p/12514914.html\n",
    "data_raw = pd.read_csv(file_path, header = 0)\n",
    "\n",
    "# values = data_raw.values # 转化为array\n",
    "# values[:,1].astype('float32') #调整数据格式\n",
    "\n",
    "# 调整时间戳\n",
    "data_raw['ts'] = pd.to_datetime(data_raw['ts'], unit='ms')\n",
    "data_raw.index=data_raw['ts']\n",
    "del data_raw['ts']\n",
    "\n",
    "# normalize\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dt_scaled = scaler.fit_transform(data_raw)  # dt_scaled is now a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2adeef64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77350946],\n",
       "       [0.77553396],\n",
       "       [0.77548335],\n",
       "       ...,\n",
       "       [0.79911934],\n",
       "       [0.80149813],\n",
       "       [0.79881567]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw\n",
    "\n",
    "dt_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "911b409e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertseries to supervised learning\n",
    "\n",
    "def series_to_supervised(data, n_in=1, n_out=1, drop_nan=True):\n",
    "    \"\"\"\n",
    "    Frame a time series as a supervised learning dataset.\n",
    "    Arguments:\n",
    "        data: Sequence of observations as a list or NumPy array.\n",
    "        n_in: Number of lag observations as input (X).\n",
    "        n_out: Number of observations as output (y).\n",
    "        dropnan: Boolean whether or not to drop rows with NaN values.\n",
    "    Returns:\n",
    "        Pandas DataFrame of series framed for supervised learning.\n",
    "    \"\"\"\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    colums, names = [],[]\n",
    "    \n",
    "    # 输入序列 (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        colums.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "\n",
    "    # 预测序列 (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        colums.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j + 1)) for j in range(n_vars)]\n",
    "        else: \n",
    "            names += [('var%d(t+%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "\n",
    "    # put it all together\n",
    "    agg = pd.concat(colums, axis=1)\n",
    "    agg.columns = names\n",
    "\n",
    "    # drop rows with NaN values\n",
    "    if drop_nan:\n",
    "        agg.dropna(inplace=True)\n",
    "\n",
    "    return agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83a80fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用前十步预测当前\n",
    "df_dt_reframed = series_to_supervised(dt_scaled,60,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fa4fc8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'训练集：train_set | 验证集：valid_set | 测试集：test_set'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 划分数据集\n",
    "split_idx_1 = int(df_dt_reframed.values.shape[0] * 0.6)\n",
    "split_idx_2 = int(df_dt_reframed.values.shape[0] * 0.8)\n",
    "train_set, valid_set, test_set = df_dt_reframed.values[:split_idx_1, :], df_dt_reframed.values[split_idx_1:split_idx_2, :], df_dt_reframed.values[split_idx_2:, :]\n",
    "'''训练集：train_set | 验证集：valid_set | 测试集：test_set'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a874068f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24420, 60)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 划分输入输出（最后一列为输出/待预测值）\n",
    "train_X, train_Y = train_set[:, :-1], train_set[:, -1]\n",
    "valid_X, valid_Y = valid_set[:, :-1], valid_set[:, -1]\n",
    "test_X, test_Y = test_set[:, :-1], test_set[:, -1]\n",
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91e527f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be 3D [samples, timesteps, dim]\n",
    "train_X = train_X.reshape((-1, train_X.shape[1], 1))\n",
    "valid_X = valid_X.reshape((-1, valid_X.shape[1], 1))\n",
    "test_X = test_X.reshape((-1, test_X.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81fe0146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "245/245 [==============================] - 38s 124ms/step - loss: 0.0604\n",
      "Epoch 2/50\n",
      "245/245 [==============================] - 32s 129ms/step - loss: 0.0065\n",
      "Epoch 3/50\n",
      "245/245 [==============================] - 28s 116ms/step - loss: 0.0058\n",
      "Epoch 4/50\n",
      "245/245 [==============================] - 29s 119ms/step - loss: 0.0050\n",
      "Epoch 5/50\n",
      "245/245 [==============================] - 29s 118ms/step - loss: 0.0045\n",
      "Epoch 6/50\n",
      "245/245 [==============================] - 29s 120ms/step - loss: 0.0041\n",
      "Epoch 7/50\n",
      "245/245 [==============================] - 31s 128ms/step - loss: 0.0039\n",
      "Epoch 8/50\n",
      "245/245 [==============================] - 30s 122ms/step - loss: 0.0033\n",
      "Epoch 9/50\n",
      "245/245 [==============================] - 29s 118ms/step - loss: 0.0029\n",
      "Epoch 10/50\n",
      "245/245 [==============================] - 29s 118ms/step - loss: 0.0027\n",
      "Epoch 11/50\n",
      "245/245 [==============================] - 29s 120ms/step - loss: 0.0023\n",
      "Epoch 12/50\n",
      "245/245 [==============================] - 30s 124ms/step - loss: 0.0020\n",
      "Epoch 13/50\n",
      "245/245 [==============================] - 29s 120ms/step - loss: 0.0018\n",
      "Epoch 14/50\n",
      "245/245 [==============================] - 30s 121ms/step - loss: 0.0016\n",
      "Epoch 15/50\n",
      "245/245 [==============================] - 31s 127ms/step - loss: 0.0015\n",
      "Epoch 16/50\n",
      "245/245 [==============================] - 31s 126ms/step - loss: 0.0014\n",
      "Epoch 17/50\n",
      "245/245 [==============================] - 30s 124ms/step - loss: 0.0012\n",
      "Epoch 18/50\n",
      "245/245 [==============================] - 30s 121ms/step - loss: 0.0012\n",
      "Epoch 19/50\n",
      "245/245 [==============================] - 32s 130ms/step - loss: 0.0010\n",
      "Epoch 20/50\n",
      "245/245 [==============================] - 34s 141ms/step - loss: 9.7644e-04\n",
      "Epoch 21/50\n",
      "245/245 [==============================] - 34s 137ms/step - loss: 8.3479e-04\n",
      "Epoch 22/50\n",
      "245/245 [==============================] - 31s 126ms/step - loss: 8.0092e-04\n",
      "Epoch 23/50\n",
      "245/245 [==============================] - 30s 122ms/step - loss: 7.9753e-04\n",
      "Epoch 24/50\n",
      "245/245 [==============================] - 32s 130ms/step - loss: 7.5701e-04\n",
      "Epoch 25/50\n",
      "245/245 [==============================] - 34s 137ms/step - loss: 6.7951e-04\n",
      "Epoch 26/50\n",
      "245/245 [==============================] - 32s 131ms/step - loss: 6.8736e-04\n",
      "Epoch 27/50\n",
      "245/245 [==============================] - 32s 130ms/step - loss: 7.2175e-04\n",
      "Epoch 28/50\n",
      "245/245 [==============================] - 32s 130ms/step - loss: 6.6729e-04\n",
      "Epoch 29/50\n",
      "245/245 [==============================] - 31s 127ms/step - loss: 6.2120e-04\n",
      "Epoch 30/50\n",
      "245/245 [==============================] - 32s 129ms/step - loss: 6.2071e-04\n",
      "Epoch 31/50\n",
      "245/245 [==============================] - 29s 120ms/step - loss: 6.1449e-04\n",
      "Epoch 32/50\n",
      "245/245 [==============================] - 31s 125ms/step - loss: 5.6678e-04\n",
      "Epoch 33/50\n",
      "245/245 [==============================] - 30s 122ms/step - loss: 5.5051e-04\n",
      "Epoch 34/50\n",
      "245/245 [==============================] - 30s 121ms/step - loss: 5.6500e-04\n",
      "Epoch 35/50\n",
      "245/245 [==============================] - 29s 120ms/step - loss: 5.7061e-04\n",
      "Epoch 36/50\n",
      "245/245 [==============================] - 29s 120ms/step - loss: 5.6623e-04\n",
      "Epoch 37/50\n",
      "245/245 [==============================] - 29s 120ms/step - loss: 5.8454e-04\n",
      "Epoch 38/50\n",
      "245/245 [==============================] - 30s 122ms/step - loss: 5.2574e-04\n",
      "Epoch 39/50\n",
      "245/245 [==============================] - 30s 123ms/step - loss: 5.1845e-04\n",
      "Epoch 40/50\n",
      "245/245 [==============================] - 30s 122ms/step - loss: 5.6346e-04\n",
      "Epoch 41/50\n",
      "245/245 [==============================] - 30s 122ms/step - loss: 6.0854e-04\n",
      "Epoch 42/50\n",
      "245/245 [==============================] - 30s 121ms/step - loss: 5.7381e-04\n",
      "Epoch 43/50\n",
      "245/245 [==============================] - 31s 126ms/step - loss: 5.7881e-04\n",
      "Epoch 44/50\n",
      "245/245 [==============================] - 30s 121ms/step - loss: 5.2261e-04\n",
      "Epoch 45/50\n",
      "245/245 [==============================] - 31s 125ms/step - loss: 4.7900e-04\n",
      "Epoch 46/50\n",
      "245/245 [==============================] - 29s 120ms/step - loss: 5.0107e-04\n",
      "Epoch 47/50\n",
      "245/245 [==============================] - 33s 136ms/step - loss: 4.8287e-04\n",
      "Epoch 48/50\n",
      "245/245 [==============================] - 35s 144ms/step - loss: 4.7825e-04\n",
      "Epoch 49/50\n",
      "245/245 [==============================] - 31s 128ms/step - loss: 4.8676e-04\n",
      "Epoch 50/50\n",
      "245/245 [==============================] - 30s 121ms/step - loss: 4.8900e-04\n"
     ]
    }
   ],
   "source": [
    "# 设计网络\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units = 50, return_sequences = True, input_shape = (train_X.shape[1], 1)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units = 50, return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units = 50, return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units = 50))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units = 1))\n",
    "\n",
    "# 修改监控度量（默认 loss）：metrics=['mse']\n",
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "history = model.fit(train_X, train_Y, epochs = 50, batch_size = 100)\n",
    "\n",
    "# # evaluatethe model\n",
    "# scores =model.evaluate(test_X, test_Y)\n",
    "# #print scores\n",
    "# #lcd print(\"\\n\\n\\t%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9eb099b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.020044738426804543,\n",
       "  0.006574369966983795,\n",
       "  0.005642150528728962,\n",
       "  0.004795796703547239,\n",
       "  0.004317102953791618,\n",
       "  0.0039339568465948105,\n",
       "  0.003585958853363991,\n",
       "  0.0032764943316578865,\n",
       "  0.002851820085197687,\n",
       "  0.0025752047076821327,\n",
       "  0.0022582109086215496,\n",
       "  0.0020171424839645624,\n",
       "  0.0017851293087005615,\n",
       "  0.001609625993296504,\n",
       "  0.0014679612359032035,\n",
       "  0.0013391454704105854,\n",
       "  0.001189196016639471,\n",
       "  0.0010916643077507615,\n",
       "  0.0009741337853483856,\n",
       "  0.0008762428187765181,\n",
       "  0.0008334920858033001,\n",
       "  0.0008078789687715471,\n",
       "  0.0007480327622033656,\n",
       "  0.0007036455208435655,\n",
       "  0.000679460063111037,\n",
       "  0.0006917577120475471,\n",
       "  0.0006837324472144246,\n",
       "  0.0006697788485325873,\n",
       "  0.00061029102653265,\n",
       "  0.0006319688982330263,\n",
       "  0.0006318446830846369,\n",
       "  0.0005821312661282718,\n",
       "  0.0006136958836577833,\n",
       "  0.0005753532750532031,\n",
       "  0.000590311479754746,\n",
       "  0.0005672619445249438,\n",
       "  0.0005493147764354944,\n",
       "  0.0005518516409210861,\n",
       "  0.0005324206431396306,\n",
       "  0.0005433905171230435,\n",
       "  0.0005447273142635822,\n",
       "  0.000515066902153194,\n",
       "  0.0005288757383823395,\n",
       "  0.0005159638240002096,\n",
       "  0.0005013188347220421,\n",
       "  0.0004993891343474388,\n",
       "  0.0005181736196391284,\n",
       "  0.0004965721745975316,\n",
       "  0.0005000425153411925,\n",
       "  0.0004998169606551528]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.summary()\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99bf9caf",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0.8144549  0.80347201 0.8001822  ... 0.79911934 0.80149813 0.79881567].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-9fcb53ae3afe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mreal_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\kai\\scoop\\apps\\python\\3.9.4\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m         X = check_array(X, copy=self.copy, dtype=FLOAT_DTYPES,\n\u001b[0m\u001b[0;32m    459\u001b[0m                         force_all_finite=\"allow-nan\")\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kai\\scoop\\apps\\python\\3.9.4\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kai\\scoop\\apps\\python\\3.9.4\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[1;31m# If input is 1D raise error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 637\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    638\u001b[0m                     \u001b[1;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0.8144549  0.80347201 0.8001822  ... 0.79911934 0.80149813 0.79881567].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "#预测\n",
    "predicted = model.predict(test_X)\n",
    "#对预测数据还原。\n",
    "predicted = scaler.inverse_transform(predicted)\n",
    "\n",
    "real_value = scaler.inverse_transform(test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04989d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(real_value, color = 'red' , label = 'real_value')\n",
    "plt.plot(predicted, color = 'blue', label = 'predicted')\n",
    "plt.title('load predict')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Load Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
