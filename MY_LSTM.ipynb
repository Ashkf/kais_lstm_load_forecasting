{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a73fe881",
   "metadata": {},
   "source": [
    "## 利用LSTM进行负荷预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bed6623",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70929d7d",
   "metadata": {},
   "source": [
    "程序架构：\n",
    "1. 文件读取\n",
    "2. 数据预处理\n",
    "    - 转化为df\n",
    "    - 归一化\n",
    "    - 转化为监督学习df\n",
    "    - 数据集分割(6:2:2)\n",
    "3. 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "42fb6d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import requests\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892926cd",
   "metadata": {},
   "source": [
    "# Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e9cf341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "\n",
    "file_path = r'C:\\Users\\KAI\\Source\\kais_lstm_load_forecasting\\真空泵空压机(A_10000151_1).csv'\n",
    "\n",
    "# 第一行做列名(header)\\第一列做索引(id)\\解析第二列为日期\n",
    "# 参考https://www.cnblogs.com/traditional/p/12514914.html\n",
    "data_raw = pd.read_csv(file_path, header = 0)\n",
    "\n",
    "values = data_raw.values # 转化为array\n",
    "values[:,1].astype('float32') #调整数据格式\n",
    "\n",
    "# 调整时间戳\n",
    "data_raw['ts'] = pd.to_datetime(data_raw['ts'], unit='ms')\n",
    "data_raw.index=data_raw['ts']\n",
    "del data_raw['ts']\n",
    "\n",
    "# normalize\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dt_scaled = scaler.fit_transform(data_raw)  # dt_scaled is now a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9f952475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.83414313],\n",
       "       [0.83257415],\n",
       "       [0.83206802],\n",
       "       ...,\n",
       "       [0.86683875],\n",
       "       [0.92018423],\n",
       "       [0.83373823]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "911b409e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertseries to supervised learning\n",
    "\n",
    "def series_to_supervised(data, n_in=1, n_out=1, drop_nan=True):\n",
    "    \"\"\"\n",
    "    Frame a time series as a supervised learning dataset.\n",
    "    Arguments:\n",
    "        data: Sequence of observations as a list or NumPy array.\n",
    "        n_in: Number of lag observations as input (X).\n",
    "        n_out: Number of observations as output (y).\n",
    "        dropnan: Boolean whether or not to drop rows with NaN values.\n",
    "    Returns:\n",
    "        Pandas DataFrame of series framed for supervised learning.\n",
    "    \"\"\"\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    colums, names = [],[]\n",
    "    \n",
    "    # 输入序列 (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        colums.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "\n",
    "    # 预测序列 (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        colums.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j + 1)) for j in range(n_vars)]\n",
    "        else: \n",
    "            names += [('var%d(t+%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "\n",
    "    # put it all together\n",
    "    agg = pd.concat(colums, axis=1)\n",
    "    agg.columns = names\n",
    "\n",
    "    # drop rows with NaN values\n",
    "    if drop_nan:\n",
    "        agg.dropna(inplace=True)\n",
    "\n",
    "    return agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "83a80fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dt_reframed = series_to_supervised(dt_scaled,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fd2967c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.83414313, 0.83257415, 0.83206802, 0.83287782],\n",
       "       [0.83257415, 0.83206802, 0.83287782, 0.78798461],\n",
       "       [0.83206802, 0.83287782, 0.78798461, 0.78768094],\n",
       "       ...,\n",
       "       [0.79390627, 0.7887438 , 0.78813645, 0.86683875],\n",
       "       [0.7887438 , 0.78813645, 0.86683875, 0.92018423],\n",
       "       [0.78813645, 0.86683875, 0.92018423, 0.83373823]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dt_reframed.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0a816b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'训练集：train_set | 验证集：valid_set | 测试集：test_set'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 划分数据集\n",
    "split_idx_1 = int(dt_reframed.shape[0] * 0.6)\n",
    "split_idx_2 = int(dt_reframed.shape[0] * 0.8)\n",
    "train_set, valid_set, test_set = df_dt_reframed.values[:split_idx_1, :], df_dt_reframed.values[split_idx_1:split_idx_2, :], df_dt_reframed.values[split_idx_2:, :]\n",
    "'''训练集：train_set | 验证集：valid_set | 测试集：test_set'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d1e5f7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.83414313, 0.83257415, 0.83206802],\n",
       "       [0.83257415, 0.83206802, 0.83287782],\n",
       "       [0.83206802, 0.83287782, 0.78798461],\n",
       "       ...,\n",
       "       [0.78935115, 0.78884502, 0.79431117],\n",
       "       [0.78884502, 0.79431117, 0.79137565],\n",
       "       [0.79431117, 0.79137565, 0.79188177]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 划分输入输出（最后一列为输出）\n",
    "train_X, train_Y = train_set[:, :-1], train_set[:, -1]\n",
    "valid_X, valid_Y = valid_set[:, :-1], valid_set[:, -1]\n",
    "test_X, test_Y = test_set[:, :-1], test_set[:, -1]\n",
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "91e527f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24454, 1, 3) (24454,) (8152, 1, 3) (8152,)\n"
     ]
    }
   ],
   "source": [
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X_3d = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X_3d = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X_3d.shape, train_Y.shape, test_X_3d.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "81fe0146",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-cf94c08f6922>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mae'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# 设计网络\n",
    "model =Sequential()\n",
    "model.add(LSTM(5, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "# fitnetwork\n",
    "history =model.fit(train_X, train_Y, epochs=50, batch_size=72, validation_data=(test_X,test_y), verbose=2, shuffle=False)\n",
    "\n",
    "# evaluatethe model\n",
    "scores =model.evaluate(test_X, test_Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
