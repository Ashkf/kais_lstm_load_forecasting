{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a73fe881",
   "metadata": {},
   "source": [
    "## 利用LSTM进行负荷预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bed6623",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70929d7d",
   "metadata": {},
   "source": [
    "程序架构：\n",
    "1. 文件读取\n",
    "2. 数据预处理\n",
    "    - 转化为df\n",
    "    - 归一化\n",
    "    - 转化为监督学习df\n",
    "    - 数据集分割(6:2:2)\n",
    "3. 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42fb6d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import requests\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892926cd",
   "metadata": {},
   "source": [
    "# Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9cf341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "\n",
    "file_path = r'C:\\Users\\KAI\\Source\\kais_lstm_load_forecasting\\真空泵空压机(A_10000151_1).csv'\n",
    "\n",
    "# 第一行做列名(header)\\第一列做索引(id)\\解析第二列为日期\n",
    "# 参考https://www.cnblogs.com/traditional/p/12514914.html\n",
    "data_raw = pd.read_csv(file_path, header = 0)\n",
    "\n",
    "values = data_raw.values # 转化为array\n",
    "values[:,1].astype('float32') #调整数据格式\n",
    "\n",
    "# 调整时间戳\n",
    "data_raw['ts'] = pd.to_datetime(data_raw['ts'], unit='ms')\n",
    "data_raw.index=data_raw['ts']\n",
    "del data_raw['ts']\n",
    "\n",
    "# normalize\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dt_scaled = scaler.fit_transform(data_raw)  # dt_scaled is now a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2adeef64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.83414313],\n",
       "       [0.83257415],\n",
       "       [0.83206802],\n",
       "       ...,\n",
       "       [0.86683875],\n",
       "       [0.92018423],\n",
       "       [0.83373823]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "911b409e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertseries to supervised learning\n",
    "\n",
    "def series_to_supervised(data, n_in=1, n_out=1, drop_nan=True):\n",
    "    \"\"\"\n",
    "    Frame a time series as a supervised learning dataset.\n",
    "    Arguments:\n",
    "        data: Sequence of observations as a list or NumPy array.\n",
    "        n_in: Number of lag observations as input (X).\n",
    "        n_out: Number of observations as output (y).\n",
    "        dropnan: Boolean whether or not to drop rows with NaN values.\n",
    "    Returns:\n",
    "        Pandas DataFrame of series framed for supervised learning.\n",
    "    \"\"\"\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    colums, names = [],[]\n",
    "    \n",
    "    # 输入序列 (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        colums.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "\n",
    "    # 预测序列 (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        colums.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j + 1)) for j in range(n_vars)]\n",
    "        else: \n",
    "            names += [('var%d(t+%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "\n",
    "    # put it all together\n",
    "    agg = pd.concat(colums, axis=1)\n",
    "    agg.columns = names\n",
    "\n",
    "    # drop rows with NaN values\n",
    "    if drop_nan:\n",
    "        agg.dropna(inplace=True)\n",
    "\n",
    "    return agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83a80fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用前十步预测当前\n",
    "df_dt_reframed = series_to_supervised(dt_scaled,10,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd2967c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        var1(t-10)  var1(t-9)  var1(t-8)  var1(t-7)  var1(t-6)  var1(t-5)  \\\n",
       "10       0.834143   0.832574   0.832068   0.832878   0.787985   0.787681   \n",
       "11       0.832574   0.832068   0.832878   0.787985   0.787681   0.789149   \n",
       "12       0.832068   0.832878   0.787985   0.787681   0.789149   0.790161   \n",
       "13       0.832878   0.787985   0.787681   0.789149   0.790161   0.787428   \n",
       "14       0.787985   0.787681   0.789149   0.790161   0.787428   0.791426   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "40756    0.795020   0.791173   0.795425   0.792337   0.791679   0.793754   \n",
       "40757    0.791173   0.795425   0.792337   0.791679   0.793754   0.790768   \n",
       "40758    0.795425   0.792337   0.791679   0.793754   0.790768   0.792236   \n",
       "40759    0.792337   0.791679   0.793754   0.790768   0.792236   0.791578   \n",
       "40760    0.791679   0.793754   0.790768   0.792236   0.791578   0.793906   \n",
       "\n",
       "       var1(t-4)  var1(t-3)  var1(t-2)  var1(t-1)   var1(t)  \n",
       "10      0.789149   0.790161   0.787428   0.791426  0.789047  \n",
       "11      0.790161   0.787428   0.791426   0.789047  0.792641  \n",
       "12      0.787428   0.791426   0.789047   0.792641  0.791477  \n",
       "13      0.791426   0.789047   0.792641   0.791477  0.793198  \n",
       "14      0.789047   0.792641   0.791477   0.793198  0.790212  \n",
       "...          ...        ...        ...        ...       ...  \n",
       "40756   0.790768   0.792236   0.791578   0.793906  0.788744  \n",
       "40757   0.792236   0.791578   0.793906   0.788744  0.788136  \n",
       "40758   0.791578   0.793906   0.788744   0.788136  0.866839  \n",
       "40759   0.793906   0.788744   0.788136   0.866839  0.920184  \n",
       "40760   0.788744   0.788136   0.866839   0.920184  0.833738  \n",
       "\n",
       "[40751 rows x 11 columns]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dt_reframed.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fa4fc8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'训练集：train_set | 验证集：valid_set | 测试集：test_set'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 划分数据集\n",
    "split_idx_1 = int(df_dt_reframed.values.shape[0] * 0.6)\n",
    "split_idx_2 = int(df_dt_reframed.values.shape[0] * 0.8)\n",
    "train_set, valid_set, test_set = df_dt_reframed.values[:split_idx_1, :], df_dt_reframed.values[split_idx_1:split_idx_2, :], df_dt_reframed.values[split_idx_2:, :]\n",
    "'''训练集：train_set | 验证集：valid_set | 测试集：test_set'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a874068f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24450, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 划分输入输出（最后一列为输出/待预测值）\n",
    "train_X, train_Y = train_set[:, :-1], train_set[:, -1]\n",
    "valid_X, valid_Y = valid_set[:, :-1], valid_set[:, -1]\n",
    "test_X, test_Y = test_set[:, :-1], test_set[:, -1]\n",
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91e527f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.83414313]\n",
      "  [0.83257415]\n",
      "  [0.83206802]\n",
      "  ...\n",
      "  [0.79016095]\n",
      "  [0.78742788]\n",
      "  [0.79142626]]\n",
      "\n",
      " [[0.83257415]\n",
      "  [0.83206802]\n",
      "  [0.83287782]\n",
      "  ...\n",
      "  [0.78742788]\n",
      "  [0.79142626]\n",
      "  [0.78904747]]\n",
      "\n",
      " [[0.83206802]\n",
      "  [0.83287782]\n",
      "  [0.78798461]\n",
      "  ...\n",
      "  [0.79142626]\n",
      "  [0.78904747]\n",
      "  [0.79264096]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.79947363]\n",
      "  [0.79613321]\n",
      "  [0.794463  ]\n",
      "  ...\n",
      "  [0.79137565]\n",
      "  [0.79188177]\n",
      "  [0.79152748]]\n",
      "\n",
      " [[0.79613321]\n",
      "  [0.794463  ]\n",
      "  [0.79081891]\n",
      "  ...\n",
      "  [0.79188177]\n",
      "  [0.79152748]\n",
      "  [0.79056585]]\n",
      "\n",
      " [[0.794463  ]\n",
      "  [0.79081891]\n",
      "  [0.78935115]\n",
      "  ...\n",
      "  [0.79152748]\n",
      "  [0.79056585]\n",
      "  [0.7907683 ]]]\n"
     ]
    }
   ],
   "source": [
    "# reshape input to be 3D [samples, timesteps, dim]\n",
    "train_X = train_X.reshape((-1, train_X.shape[1], 1))\n",
    "valid_X = valid_X.reshape((-1, valid_X.shape[1], 1))\n",
    "test_X = test_X.reshape((-1, test_X.shape[1], 1))\n",
    "print(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fe0146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设计网络\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units = 50, return_sequences = True, input_shape = (train_X.shape[1], 1)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units = 50, return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units = 50, return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units = 50))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units = 1))\n",
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "model.fit(train_X, train_Y, epochs = 20, batch_size = 100)\n",
    "# # fitnetwork\n",
    "# history =model.fit(train_X, train_Y, epochs=50, batch_size=100, validation_data=(valid_X,valid_Y), verbose=2, shuffle=False)\n",
    "\n",
    "# # evaluatethe model\n",
    "# scores =model.evaluate(test_X, test_Y)\n",
    "# #print scores\n",
    "# #lcd print(\"\\n\\n\\t%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb099b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bf9caf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#预测\n",
    "predicted = model.predict(test_X)\n",
    "#对预测数据还原。\n",
    "predicted = scaler.inverse_transform(predicted)\n",
    "\n",
    "real_value = scaler.inverse_transform(test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04989d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(real_value, color = 'red' , label = 'real_value')\n",
    "plt.plot(predicted, color = 'blue', label = 'predicted')\n",
    "plt.title('load predict')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Load Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524e674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# invert scaling for forecast\n",
    "#inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat,0)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "#pyplot.plot(history.history['yhat'], label='actual')\n",
    "#pyplot.plot(history.history['inv_yhat'], label='forecast')\n",
    "#pyplot.legend()\n",
    "#pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
